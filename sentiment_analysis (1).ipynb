{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cfe02179",
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import classification_report,accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2ac115c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "92d40679",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv('C:/Users/LENOVO/OneDrive/Desktop/project/sentimental/sentimental/sentiment_dataset_50k.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5ab48016",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The printer did its job as expected.</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This laptop is fantastic and exceeded my expec...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Extremely dissatisfied with this headphone.</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The mouse worked perfectly and made my day!</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>It's an average headphone. Just fine.</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>The mouse worked perfectly and made my day!</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>The keyboard is neither good nor bad.</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>Extremely dissatisfied with this tablet.</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>This printer is fantastic and exceeded my expe...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>This microwave is terrible and a waste of money.</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text sentiment\n",
       "0                   The printer did its job as expected.   neutral\n",
       "1      This laptop is fantastic and exceeded my expec...  positive\n",
       "2            Extremely dissatisfied with this headphone.  negative\n",
       "3            The mouse worked perfectly and made my day!  positive\n",
       "4                  It's an average headphone. Just fine.   neutral\n",
       "...                                                  ...       ...\n",
       "49995        The mouse worked perfectly and made my day!  positive\n",
       "49996              The keyboard is neither good nor bad.   neutral\n",
       "49997           Extremely dissatisfied with this tablet.  negative\n",
       "49998  This printer is fantastic and exceeded my expe...  positive\n",
       "49999   This microwave is terrible and a waste of money.  negative\n",
       "\n",
       "[50000 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7447cb2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "935e964b-80d2-4939-ab8c-b0d0000b23c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\LENOVO\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\LENOVO\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Define preprocessing function\n",
    "def preprocess(text):\n",
    "    text = text.lower()\n",
    "    tokens = re.findall(r'\\b[a-z]+\\b', text)  # only alphabetic words\n",
    "    tokens = [word for word in tokens if word not in stopwords.words('english')]\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "df['clean_text'] = df['text'].apply(preprocess)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "951b48e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(df['clean_text'])  #  Now this column exists\n",
    "y = df['sentiment']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "588c7b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4a57f04f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a classifier\n",
    "model = DecisionTreeClassifier(max_depth=9).fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "105dbc66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.80      0.89      2922\n",
      "     neutral       1.00      1.00      1.00      3038\n",
      "    positive       0.88      1.00      0.93      4040\n",
      "\n",
      "    accuracy                           0.94     10000\n",
      "   macro avg       0.96      0.93      0.94     10000\n",
      "weighted avg       0.95      0.94      0.94     10000\n",
      "\n",
      "Accuracy score: 94.24 %\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "y_pred = model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Accuracy score:\",accuracy_score(y_test, y_pred)*100,(\"%\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "27552bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict sentiment of new sentence\n",
    "def predict_sentiment(sentence):\n",
    "    processed = preprocess(sentence)\n",
    "    vectorized = vectorizer.transform([processed])\n",
    "    return model.predict(vectorized)[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "10eb85fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted sentiment for the sentence is: positive\n"
     ]
    }
   ],
   "source": [
    "#user input\n",
    "new_sentence=input(\"Enter a sentence to predict sentiment: \")\n",
    "predicted_sentiment = predict_sentiment(new_sentence)\n",
    "print(f\"The predicted sentiment for the sentence is: {predicted_sentiment}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7031038e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1e7921f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "with open(\"model.pkl\", \"wb\") as f:\n",
    "    pickle.dump(model, f)\n",
    "\n",
    "# Save vectorizer\n",
    "with open(\"vectorizer.pkl\", \"wb\") as f:\n",
    "    pickle.dump(vectorizer, f)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
